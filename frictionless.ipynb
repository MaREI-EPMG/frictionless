{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "frictionless.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOs+eJwnljpiNg4cQb9ajeN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CiaraAOC/frictionless/blob/main/frictionless.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qLxYQ1hsle1f",
        "outputId": "f6e15cb8-8a6b-4b19-bf3f-dd13361369bc"
      },
      "source": [
        "!pip install frictionless \n",
        "import frictionless\n",
        "!pip install pyjstat\n",
        "import pyjstat\n",
        "from pyjstat import pyjstat\n",
        "import pandas as pd\n",
        "from pprint import pprint"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting frictionless\n",
            "  Downloading frictionless-4.14.2-py2.py3-none-any.whl (233 kB)\n",
            "\u001b[?25l\r\u001b[K     |█▍                              | 10 kB 26.8 MB/s eta 0:00:01\r\u001b[K     |██▉                             | 20 kB 23.6 MB/s eta 0:00:01\r\u001b[K     |████▏                           | 30 kB 12.0 MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 40 kB 9.1 MB/s eta 0:00:01\r\u001b[K     |███████                         | 51 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 61 kB 4.5 MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 71 kB 4.8 MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 81 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 92 kB 4.5 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 102 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 112 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 122 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 133 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 143 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 153 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 163 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 174 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 184 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 194 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 204 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 215 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 225 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 233 kB 5.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8 in /usr/local/lib/python3.7/dist-packages (from frictionless) (2.8.1)\n",
            "Requirement already satisfied: click<7.2.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from frictionless) (7.1.2)\n",
            "Collecting typer[all]>=0.3\n",
            "  Downloading typer-0.3.2-py3-none-any.whl (21 kB)\n",
            "Collecting validators>=0.18\n",
            "  Downloading validators-0.18.2-py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: python-slugify>=1.2 in /usr/local/lib/python3.7/dist-packages (from frictionless) (5.0.2)\n",
            "Requirement already satisfied: chardet>=3.0 in /usr/local/lib/python3.7/dist-packages (from frictionless) (3.0.4)\n",
            "Collecting pyyaml>=5.3\n",
            "  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n",
            "\u001b[K     |████████████████████████████████| 636 kB 52.1 MB/s \n",
            "\u001b[?25hCollecting simpleeval>=0.9\n",
            "  Downloading simpleeval-0.9.10.tar.gz (26 kB)\n",
            "Requirement already satisfied: requests>=2.10 in /usr/local/lib/python3.7/dist-packages (from frictionless) (2.23.0)\n",
            "Collecting petl>=1.6\n",
            "  Downloading petl-1.7.4.tar.gz (245 kB)\n",
            "\u001b[K     |████████████████████████████████| 245 kB 45.3 MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting stringcase>=1.2\n",
            "  Downloading stringcase-1.2.0.tar.gz (3.0 kB)\n",
            "Requirement already satisfied: jsonschema>=2.5 in /usr/local/lib/python3.7/dist-packages (from frictionless) (2.6.0)\n",
            "Collecting rfc3986>=1.4\n",
            "  Downloading rfc3986-1.5.0-py2.py3-none-any.whl (31 kB)\n",
            "Collecting isodate>=0.6\n",
            "  Downloading isodate-0.6.0-py2.py3-none-any.whl (45 kB)\n",
            "\u001b[K     |████████████████████████████████| 45 kB 3.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from isodate>=0.6->frictionless) (1.15.0)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify>=1.2->frictionless) (1.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.10->frictionless) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.10->frictionless) (2021.5.30)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.10->frictionless) (1.24.3)\n",
            "Collecting shellingham<2.0.0,>=1.3.0\n",
            "  Downloading shellingham-1.4.0-py2.py3-none-any.whl (9.4 kB)\n",
            "Collecting colorama<0.5.0,>=0.4.3\n",
            "  Downloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: decorator>=3.4.0 in /usr/local/lib/python3.7/dist-packages (from validators>=0.18->frictionless) (4.4.2)\n",
            "Building wheels for collected packages: petl, simpleeval, stringcase\n",
            "  Building wheel for petl (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for petl: filename=petl-1.7.4-py3-none-any.whl size=216998 sha256=c41b46e900a04fe2000f32ae5c256ab22495d25065fc80266bd662e5bcde9294\n",
            "  Stored in directory: /root/.cache/pip/wheels/75/23/fb/a0e8e350a8718579b0cde55163df77b94de835d7d116388fa5\n",
            "  Building wheel for simpleeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for simpleeval: filename=simpleeval-0.9.10-py3-none-any.whl size=13769 sha256=f50f97cfa39619c74bc17bf49397319ed685abdc7ec3a4f9ed005c4098b9849a\n",
            "  Stored in directory: /root/.cache/pip/wheels/d4/aa/50/0b420d1eabad3c16a82368935c6a2050955bc3ee2a11ee4e06\n",
            "  Building wheel for stringcase (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for stringcase: filename=stringcase-1.2.0-py3-none-any.whl size=3586 sha256=cf939522cd0962d57382268f1bde37a7e6be7f851347bd4e86b50f4b7643f739\n",
            "  Stored in directory: /root/.cache/pip/wheels/86/ab/a3/a8fa7e0a07e80f547e03468c03827f8257f7339327986faed1\n",
            "Successfully built petl simpleeval stringcase\n",
            "Installing collected packages: typer, shellingham, colorama, validators, stringcase, simpleeval, rfc3986, pyyaml, petl, isodate, frictionless\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed colorama-0.4.4 frictionless-4.14.2 isodate-0.6.0 petl-1.7.4 pyyaml-5.4.1 rfc3986-1.5.0 shellingham-1.4.0 simpleeval-0.9.10 stringcase-1.2.0 typer-0.3.2 validators-0.18.2\n",
            "Collecting pyjstat\n",
            "  Downloading pyjstat-2.2.0.tar.gz (891 kB)\n",
            "\u001b[K     |████████████████████████████████| 891 kB 4.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from pyjstat) (1.1.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from pyjstat) (2.23.0)\n",
            "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from pandas->pyjstat) (1.19.5)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->pyjstat) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->pyjstat) (2.8.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->pyjstat) (1.15.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->pyjstat) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->pyjstat) (2021.5.30)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->pyjstat) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->pyjstat) (2.10)\n",
            "Building wheels for collected packages: pyjstat\n",
            "  Building wheel for pyjstat (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyjstat: filename=pyjstat-2.2.0-py3-none-any.whl size=18870 sha256=288ad0b4ac74628eafaa1a7ffddb797a94edb06411bb589a0a2cd562cbc6b433\n",
            "  Stored in directory: /root/.cache/pip/wheels/a7/9a/97/1cb33acc90d717bebb2a2b54f785fceceefd40090b8532b970\n",
            "Successfully built pyjstat\n",
            "Installing collected packages: pyjstat\n",
            "Successfully installed pyjstat-2.2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4FNmVe7CjjWA"
      },
      "source": [
        "from pyjstat import pyjstat\n",
        "dataset = pyjstat.Dataset.read('https://ws.cso.ie/public/api.restful/PxStat.Data.Cube_API.ReadDataset/THA18/JSON-stat/2.0/en')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xPaqdGhtmo6z",
        "outputId": "ad9e9ee8-8cb4-42d3-8d06-0d57e60bdff4"
      },
      "source": [
        "df = dataset.write('dataframe')\n",
        "print(df)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                            Statistic  Year  ... Year of Registration      value\n",
            "0                  Vehicle Population  2015  ...            All years  1992819.0\n",
            "1                  Vehicle Population  2015  ...       1999 or before    90989.0\n",
            "2                  Vehicle Population  2015  ...                 2000    77870.0\n",
            "3                  Vehicle Population  2015  ...                 2001    70838.0\n",
            "4                  Vehicle Population  2015  ...                 2002    86226.0\n",
            "...                               ...   ...  ...                  ...        ...\n",
            "1140475  Average Kilometres Travelled  2019  ...                 2015    15169.0\n",
            "1140476  Average Kilometres Travelled  2019  ...                 2016    13008.0\n",
            "1140477  Average Kilometres Travelled  2019  ...                 2017    15019.0\n",
            "1140478  Average Kilometres Travelled  2019  ...                 2018    13059.0\n",
            "1140479  Average Kilometres Travelled  2019  ...                 2019    13126.0\n",
            "\n",
            "[1140480 rows x 8 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FN-ZzTjfmp5L",
        "outputId": "6f2848a2-8adb-4067-b51c-45fe92547463"
      },
      "source": [
        "from frictionless import describe #generates metadata describing layout/contents of data\n",
        "\n",
        "resource = describe(df)\n",
        "pprint(resource)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'data':                             Statistic  Year  ... Year of Registration      value\n",
            "0                  Vehicle Population  2015  ...            All years  1992819.0\n",
            "1                  Vehicle Population  2015  ...       1999 or before    90989.0\n",
            "2                  Vehicle Population  2015  ...                 2000    77870.0\n",
            "3                  Vehicle Population  2015  ...                 2001    70838.0\n",
            "4                  Vehicle Population  2015  ...                 2002    86226.0\n",
            "...                               ...   ...  ...                  ...        ...\n",
            "1140475  Average Kilometres Travelled  2019  ...                 2015    15169.0\n",
            "1140476  Average Kilometres Travelled  2019  ...                 2016    13008.0\n",
            "1140477  Average Kilometres Travelled  2019  ...                 2017    15019.0\n",
            "1140478  Average Kilometres Travelled  2019  ...                 2018    13059.0\n",
            "1140479  Average Kilometres Travelled  2019  ...                 2019    13126.0\n",
            "\n",
            "[1140480 rows x 8 columns],\n",
            " 'format': 'pandas',\n",
            " 'hashing': 'md5',\n",
            " 'name': 'memory',\n",
            " 'profile': 'tabular-data-resource',\n",
            " 'schema': {'fields': [{'name': 'Statistic', 'type': 'string'},\n",
            "                       {'name': 'Year', 'type': 'string'},\n",
            "                       {'name': 'Type of Ownership', 'type': 'string'},\n",
            "                       {'name': 'Engine Capacity cc', 'type': 'string'},\n",
            "                       {'name': 'Fuel Type', 'type': 'string'},\n",
            "                       {'name': 'County of Ownership', 'type': 'string'},\n",
            "                       {'name': 'Year of Registration', 'type': 'string'},\n",
            "                       {'name': 'value', 'type': 'number'}]},\n",
            " 'scheme': ''}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HR7v6lavmuhb"
      },
      "source": [
        "from frictionless import extract #read and normalise data\n",
        "\n",
        "rows = extract(df)\n",
        "#pprint(rows)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0yeTydOwmxpM",
        "outputId": "dfec5fe2-1839-40ea-b842-772121e622b2"
      },
      "source": [
        "from frictionless import validate #detects errors in the file\n",
        "\n",
        "report = validate(df)\n",
        "pprint(report.task.scope)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['hash-count-error',\n",
            " 'byte-count-error',\n",
            " 'field-count-error',\n",
            " 'row-count-error',\n",
            " 'blank-header',\n",
            " 'extra-label',\n",
            " 'missing-label',\n",
            " 'blank-label',\n",
            " 'duplicate-label',\n",
            " 'incorrect-label',\n",
            " 'blank-row',\n",
            " 'primary-key-error',\n",
            " 'foreign-key-error',\n",
            " 'extra-cell',\n",
            " 'missing-cell',\n",
            " 'type-error',\n",
            " 'constraint-error',\n",
            " 'unique-error']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EMez8T_sm8YV"
      },
      "source": [
        "from frictionless import Resource, FrictionlessException\n",
        "\n",
        "try:\n",
        "    resource = Resource(df)\n",
        "except FrictionlessException as exception:\n",
        "    pprint(exception.error)\n",
        "    # Prints the SchemaError metadata in this case"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LLU5ckus02bk",
        "outputId": "17631f85-b54e-4860-f862-813085cd1392"
      },
      "source": [
        "from pprint import pprint\n",
        "from frictionless import validate, checks\n",
        "\n",
        "checks = [checks.sequential_value(field_name='Statistic')]\n",
        "report = validate(df, checks=checks)\n",
        "pprint(report.flatten([\"rowPosition\", \"fieldPosition\", \"code\", \"note\"]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[2, 1, 'sequential-value', 'the value is not sequential'],\n",
            " [None, None, 'task-error', 'exceeded memory limit \"1000MB\"']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R3itM7bW0_U5"
      },
      "source": [
        "from frictionless import Resource, transform, steps\n",
        "\n",
        "# Define source resource\n",
        "source = Resource(name='main', path=df)\n",
        "# Apply transform steps\n",
        "target = transform(\n",
        "    source,\n",
        "    steps=[\n",
        "        steps.table_normalize()\n",
        "    ],\n",
        ")\n",
        "\n",
        "# Print resulting schema and data\n",
        "pprint(target.schema)\n",
        "print(target)\n",
        "print(target.data)\n",
        "pprint(source.read_lists())\n",
        "pprint(target.resource_names)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IIkLNZMknI3p"
      },
      "source": [
        "def clean(resource):\n",
        "  current = resource.to_copy\n",
        "\n",
        "source = describe(df)\n",
        "target = transform(\n",
        "    source,\n",
        "    steps=[\n",
        "        clean,\n",
        "        steps.table_write(path=\"THA18.xlsx\"),\n",
        "    ],\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oKbX404X3Z-x"
      },
      "source": [
        "from pprint import pprint\n",
        "from frictionless import Package, Resource, transform, steps\n",
        "\n",
        "source = Resource(path=df)\n",
        "target = transform(\n",
        "    source,\n",
        "    steps=[\n",
        "        steps.table_normalize(),\n",
        "        steps.table_pivot(f1=\"Statistic\", f2=\"Year\", f3=\"Type of Ownership\", aggfun=sum),\n",
        "    ]\n",
        ")\n",
        "pprint(target.schema)\n",
        "pprint(target.read_rows())\n",
        "pprint(target)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QDyx8ked3tkK"
      },
      "source": [
        "from pprint import pprint\n",
        "from frictionless import Package, Resource, transform, steps\n",
        "\n",
        "source = Resource(path=df)\n",
        "target = transform(\n",
        "    source,\n",
        "    steps=[\n",
        "        steps.table_normalize(),\n",
        "        steps.table_transpose(),\n",
        "    ]\n",
        ")\n",
        "pprint(target.schema)\n",
        "pprint(target.read_rows())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bJamuzJa4Jjx"
      },
      "source": [
        "from pprint import pprint\n",
        "from frictionless import Package, Resource, transform, steps\n",
        "\n",
        "source = Resource(path=df)\n",
        "target = transform(\n",
        "    source,\n",
        "   steps=[\n",
        "        steps.cell_set(field_name=\"Statistic\", value=\"bad\"),\n",
        "        steps.table_validate(),\n",
        "    ]\n",
        ")\n",
        "pprint(target.schema)\n",
        "try:\n",
        "  pprint(target.read_rows())\n",
        "except Exception as exception:\n",
        "  pprint(exception)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-W6eSCfg4L5R"
      },
      "source": [
        "source = Resource(path=df)\n",
        "target = transform(\n",
        "    source,\n",
        "    steps=[\n",
        "      steps.table_debug(function=print),\n",
        "    ],\n",
        ")\n",
        "pprint(target)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KzKQJc1a4Oxj"
      },
      "source": [
        "from pprint import pprint\n",
        "from frictionless import Package, Resource, transform, steps\n",
        "\n",
        "source = Package(resources=[Resource(name='main', path=df)])\n",
        "target = transform(\n",
        "    source,\n",
        "    steps=[\n",
        "        steps.resource_add(name='extra', path=df),\n",
        "    ],\n",
        ")\n",
        "pprint(target.resource_names)\n",
        "pprint(target.get_resource('extra').schema)\n",
        "pprint(target.get_resource('extra').read_rows())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "86tGVGFj4U1t"
      },
      "source": [
        "from pprint import pprint\n",
        "from frictionless import Package, Resource, transform, steps\n",
        "\n",
        "source = Package(resources=[Resource(name='main', path=df)])\n",
        "target = transform(\n",
        "    source,\n",
        "    steps=[\n",
        "        steps.resource_add(name='extra', path=df),\n",
        "        steps.resource_transform(name='main', steps=[\n",
        "            steps.table_merge(resource='extra'),\n",
        "            steps.row_sort(field_names=['Statistic'])\n",
        "        ]),\n",
        "        steps.resource_remove(name=\"extra\"),\n",
        "    ],\n",
        ")\n",
        "pprint(target.resource_names)\n",
        "pprint(target.get_resource('main').schema)\n",
        "pprint(target.get_resource('main').read_rows())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jBVdOthP4YoH"
      },
      "source": [
        "from pprint import pprint\n",
        "from frictionless import Package, Resource, transform, steps\n",
        "\n",
        "source = Resource(path=df)\n",
        "target = transform(\n",
        "    source,\n",
        "    steps=[\n",
        "        steps.field_filter(names=[\"Year\", \"County of Ownership\"]),\n",
        "    ]\n",
        ")\n",
        "pprint(target.schema)\n",
        "pprint(target.read_rows())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wasdHzQC45Gk"
      },
      "source": [
        "from pprint import pprint\n",
        "from frictionless import Package, Resource, transform, steps\n",
        "\n",
        "source = Resource(path=df)\n",
        "target = transform(\n",
        "    source,\n",
        "    steps=[\n",
        "        steps.field_move(name=\"Statistic\", position=2),\n",
        "    ]\n",
        ")\n",
        "pprint(target.schema)\n",
        "pprint(target.read_rows())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HjHEzl2L49lc"
      },
      "source": [
        "from pprint import pprint\n",
        "from frictionless import Package, Resource, transform, steps\n",
        "\n",
        "source = Resource(path=df)\n",
        "target = transform(\n",
        "    source,\n",
        "    steps=[\n",
        "        steps.field_split(name=\"Type of Ownership\", to_names=[\"Male\", \"Female\"], pattern=\"a\"),\n",
        "    ]\n",
        ")\n",
        "pprint(target.schema)\n",
        "pprint(target.read_rows())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QG_b6T8C5IIw"
      },
      "source": [
        "from frictionless import Parser\n",
        "\n",
        "class HtmlParser(Parser):\n",
        "    requires_loader = True\n",
        "    supported_types = [\n",
        "        \"string\",\n",
        "    ]\n",
        "\n",
        "    # Read\n",
        "\n",
        "    def read_list_stream_create(self):\n",
        "        pq = helpers.import_from_plugin(\"pyquery\", plugin=\"html\").PyQuery\n",
        "        dialect = self.resource.dialect\n",
        "\n",
        "        # Get Page content\n",
        "        page = pq(self.loader.text_stream.read(), parser=\"html\")\n",
        "\n",
        "        # Find required table\n",
        "        if dialect.selector:\n",
        "            table = pq(page.find(dialect.selector)[0])\n",
        "        else:\n",
        "            table = page\n",
        "\n",
        "        # Stream headers\n",
        "        data = (\n",
        "            table.children(\"thead\").children(\"tr\")\n",
        "            + table.children(\"thead\")\n",
        "            + table.children(\"tr\")\n",
        "            + table.children(\"tbody\").children(\"tr\")\n",
        "        )\n",
        "        data = [pq(r) for r in data if len(r) > 0]\n",
        "        first_row = data.pop(0)\n",
        "        headers = [pq(th).text() for th in first_row.find(\"th,td\")]\n",
        "        yield headers\n",
        "\n",
        "        # Stream data\n",
        "        data = [pq(tr).find(\"td\") for tr in data]\n",
        "        data = [[pq(td).text() for td in tr] for tr in data if len(tr) > 0]\n",
        "        yield from data\n",
        "\n",
        "    # Write\n",
        "\n",
        "    def write_row_stream(self, resource):\n",
        "        source = resource\n",
        "        target = self.resource\n",
        "        html = \"<html><body><table>\\n\"\n",
        "        with source:\n",
        "            for row in source.row_stream:\n",
        "                if row.row_number == 1:\n",
        "                    html += \"<tr>\"\n",
        "                    for name in row.field_names:\n",
        "                        html += f\"<td>{name}</td>\"\n",
        "                    html += \"</tr>\\n\"\n",
        "                cells = row.to_list(types=self.supported_types)\n",
        "                html += \"<tr>\"\n",
        "                for cell in cells:\n",
        "                    html += f\"<td>{cell}</td>\"\n",
        "                html += \"</tr>\\n\"\n",
        "        html += \"</table></body></html>\"\n",
        "        with tempfile.NamedTemporaryFile(\"wt\", delete=False) as file:\n",
        "            file.write(html)\n",
        "        loader = system.create_loader(target)\n",
        "        result = loader.write_byte_stream(file.name)\n",
        "        return result\n",
        "        pprint(target)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v6JFrrj15I6G"
      },
      "source": [
        "from frictionless import Parser\n",
        "\n",
        "class HtmlParser(Parser):\n",
        "    requires_loader = True\n",
        "    supported_types = [\n",
        "        \"string\",\n",
        "    ]\n",
        "\n",
        "    # Read\n",
        "\n",
        "    def read_list_stream_create(self):\n",
        "        pq = helpers.import_from_plugin(\"pyquery\", plugin=\"html\").PyQuery\n",
        "        dialect = self.resource.dialect\n",
        "\n",
        "        # Get Page content\n",
        "        page = pq(self.loader.text_stream.read(), parser=\"html\")\n",
        "\n",
        "        # Find required table\n",
        "        if dialect.selector:\n",
        "            table = pq(page.find(dialect.selector)[0])\n",
        "        else:\n",
        "            table = page\n",
        "\n",
        "        # Stream headers\n",
        "        data = (\n",
        "            table.children(\"thead\").children(\"tr\")\n",
        "            + table.children(\"thead\")\n",
        "            + table.children(\"tr\")\n",
        "            + table.children(\"tbody\").children(\"tr\")\n",
        "        )\n",
        "        data = [pq(r) for r in data if len(r) > 0]\n",
        "        first_row = data.pop(0)\n",
        "        headers = [pq(th).text() for th in first_row.find(\"th,td\")]\n",
        "        yield headers\n",
        "\n",
        "        # Stream data\n",
        "        data = [pq(tr).find(\"td\") for tr in data]\n",
        "        data = [[pq(td).text() for td in tr] for tr in data if len(tr) > 0]\n",
        "        yield from data\n",
        "\n",
        "    # Write\n",
        "\n",
        "    def write_row_stream(self, resource):\n",
        "        source = resource\n",
        "        target = self.resource\n",
        "        html = \"<html><body><table>\\n\"\n",
        "        with source:\n",
        "            for row in source.row_stream:\n",
        "                if row.row_number == 1:\n",
        "                    html += \"<tr>\"\n",
        "                    for name in row.field_names:\n",
        "                        html += f\"<td>{name}</td>\"\n",
        "                    html += \"</tr>\\n\"\n",
        "                cells = row.to_list(types=self.supported_types)\n",
        "                html += \"<tr>\"\n",
        "                for cell in cells:\n",
        "                    html += f\"<td>{cell}</td>\"\n",
        "                html += \"</tr>\\n\"\n",
        "        html += \"</table></body></html>\"\n",
        "        with tempfile.NamedTemporaryFile(\"wt\", delete=False) as file:\n",
        "            file.write(html)\n",
        "        loader = system.create_loader(target)\n",
        "        result = loader.write_byte_stream(file.name)\n",
        "        return result\n",
        "        pprint(target)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WA7Dq1Pl5Mbu"
      },
      "source": [
        "import os.path\n",
        "from frictionless import Resource\n",
        "resource = Resource(df)\n",
        "from frictionless.plugins.excel import ExcelDialect\n",
        "resource.write(\"File.xlsx\", dialect=ExcelDialect(sheet='My Table'))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}